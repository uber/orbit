{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pointed-triple",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T18:05:36.552119Z",
     "start_time": "2021-04-06T18:05:36.088518Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats\n",
    "from math import pi\n",
    "from scipy.spatial.distance import cdist\n",
    "import time\n",
    "\n",
    "from orbit.models.ktrx import KTRXFull, KTRXAggregated\n",
    "from orbit.models.ktrlite import KTRLiteMAP\n",
    "from orbit.estimators.pyro_estimator import PyroEstimatorVI, PyroEstimatorMAP\n",
    "from orbit.estimators.stan_estimator import StanEstimatorMAP\n",
    "from orbit.diagnostics.metrics import smape\n",
    "from orbit.utils.features import make_fourier_series_df, make_fourier_series\n",
    "from orbit.diagnostics.plot import plot_predicted_data\n",
    "\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sublime-minneapolis",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T18:05:54.030033Z",
     "start_time": "2021-04-06T18:05:53.992761Z"
    }
   },
   "outputs": [],
   "source": [
    "def sim_data_seasonal(n, RS):\n",
    "    np.random.seed(RS)\n",
    "    # make the time varing coefs  \n",
    "    tau = np.arange(1, n+1)/n\n",
    "    data = pd.DataFrame({\n",
    "        'tau': tau,\n",
    "        'date': pd.date_range(start='1/1/2018', periods=n),\n",
    "        'beta1': 2 * tau,\n",
    "        'beta2': np.sin(2*pi*tau),\n",
    "        'beta3': np.sin(4*pi*(tau-1/8)),\n",
    "        'x1': stats.chi2.rvs(4, size=n),\n",
    "        'x2': stats.t.rvs(2, size=n),\n",
    "        'x3': stats.t.rvs(2, size=n),\n",
    "        'trend': np.cumsum(np.concatenate((np.array([1]), np.random.normal(0, 0.1, n-1)))),\n",
    "        'error': np.random.normal(0, 1, size=n) #stats.t.rvs(30, size=n),#\n",
    "    })\n",
    "    \n",
    "    # add error to the data \n",
    "    #err_cov = np.exp(-cdist(data.tau.values.reshape(n, -1), data.tau.values.reshape(n, -1), 'euclid')/10)\n",
    "    #L = np.linalg.cholesky(err_cov).T\n",
    "    #data['error2'] = L.dot(stats.chi2.rvs(100, size=n))\n",
    "    \n",
    "    data['y'] = data.x1 * data.beta1 + data.x2 * data.beta2 + data.x3 * data.beta3 + data.error\n",
    "    #data['y2'] = data.x1 * data.beta1 + data.x2 * data.beta2 + data.x3 * data.beta3 + data.error2\n",
    "    #data['y3'] = data.trend + data.x1 * data.beta1 + data.x2 * data.beta2 + data.x3 * data.beta3 + data.error\n",
    "    return(data)\n",
    "\n",
    "def sim_data_rw(n, RS, p=3):\n",
    "    np.random.seed(RS)\n",
    "\n",
    "    # initializing coefficients at zeros, simulate all coefficient values\n",
    "    lev = np.cumsum(np.concatenate((np.array([5.0]), np.random.normal(0, 0.01, n-1))))\n",
    "    beta = np.concatenate(\n",
    "        [np.random.uniform(0.05, 0.12, size=(1,p)),\n",
    "         np.random.normal(0, 0.01, size=(n-1,p))], \n",
    "            axis=0)\n",
    "    beta = np.cumsum(beta, 0)\n",
    "\n",
    "    # simulate regressors\n",
    "    covariates = np.random.normal(0, 1, (n, p))\n",
    "\n",
    "    # observation with noise\n",
    "    y = lev + (covariates * beta).sum(-1) + 0.3 * np.random.normal(0, 1, n)\n",
    "\n",
    "    regressor_col = ['x{}'.format(pp) for pp in range(1, p+1)]\n",
    "    data = pd.DataFrame(covariates, columns=regressor_col)\n",
    "    data['y'] = y\n",
    "    data['date'] = pd.date_range(start='1/1/2018', periods=len(y))\n",
    "    \n",
    "    # hack for p = 3 \n",
    "    data['beta1'] = (covariates * beta)[:,0]\n",
    "    data['beta2'] = (covariates * beta)[:,1]\n",
    "    data['beta3'] = (covariates * beta)[:,2]    \n",
    "    \n",
    "    return(data)\n",
    "\n",
    "def multiple_test(N,n, sim_type):\n",
    "    out = pd.DataFrame()\n",
    "    out['index'] = range(0, N)\n",
    "    # for hte model fit \n",
    "    out['time_1'] = 0.0\n",
    "    out['time_2'] = 0.0\n",
    "    \n",
    "    out['SSE_1'] = 0.0\n",
    "    out['SSE_2'] = 0.0\n",
    "    out['RMSE_1'] = 0.0\n",
    "    out['RMSE_2'] = 0.0\n",
    "    out['max_error_1'] = 0.0\n",
    "    out['max_error_2'] = 0.0\n",
    "    \n",
    "    # for the true values \n",
    "    out['SSE_beta1_1'] = 0.0\n",
    "    out['SSE_beta1_2'] = 0.0 \n",
    "    out['SSE_beta2_1'] = 0.0   \n",
    "    out['SSE_beta2_2'] = 0.0\n",
    "    out['SSE_beta3_2'] = 0.0\n",
    "    out['SSE_beta3_1'] = 0.0\n",
    "    \n",
    "    for i in range(0, N):\n",
    "        # simulate the data \n",
    "        if sim_type == 'sea':\n",
    "            data = sim_data_seasonal(n = n, RS = 1000+i)\n",
    "       \n",
    "        if sim_type == 'rw':\n",
    "            data = sim_data_rw(n = n, RS = 1000+i, p=3)    \n",
    "    \n",
    "        #print(data.head())\n",
    "    \n",
    "        # define stuff \n",
    "        regressor_col=['x1', 'x2', 'x3']\n",
    "        response_col = 'y'\n",
    "        # run the model \n",
    "        # run lite first \n",
    "        ktr_lite = KTRLiteMAP(\n",
    "        response_col=response_col,\n",
    "        date_col='date',\n",
    "        level_knot_scale=1,\n",
    "        seed=2000+i,\n",
    "        span_level= .1, \n",
    "        estimator_type=StanEstimatorMAP,\n",
    "        )\n",
    "        ktr_lite.fit(df=data)\n",
    "        level_knots_stan = ktr_lite._aggregate_posteriors['map']['lev_knot'][0]\n",
    "        level_knot_dates = ktr_lite._level_knot_dates\n",
    "        level_knots_stan = np.array([0] * len(level_knot_dates))\n",
    "        \n",
    "        # run full model second \n",
    "        # there are two of these \n",
    "        ktrx1 = KTRXFull(\n",
    "        response_col=response_col,\n",
    "        date_col='date',\n",
    "\n",
    "        degree_of_freedom=30,\n",
    "        level_knot_scale=.001,\n",
    "        level_knot_dates=level_knot_dates,\n",
    "        level_knots=level_knots_stan,\n",
    "\n",
    "        regressor_col=regressor_col,\n",
    "        #regressor_sign=['='] * len(regressor_col),\n",
    "        regressor_knot_pooling_loc=[0] * len(regressor_col),\n",
    "        regressor_knot_pooling_scale=[1] * len(regressor_col),\n",
    "        regressor_knot_scale=[.2] * len(regressor_col),\n",
    "        # seasonal_knots_input={},\n",
    "\n",
    "        span_coefficients=0.1,\n",
    "        rho_coefficients=0.1, #.1,.11,.12\n",
    "        prediction_percentiles=[2.5, 97.5],\n",
    "        seed=2000+i,\n",
    "        num_steps=1000,\n",
    "        num_particles=100,\n",
    "        num_sample=1000,\n",
    "        learning_rate=0.01,\n",
    "        learning_rate_total_decay=1.,\n",
    "        verbose=False,\n",
    "        message=100,\n",
    "        n_bootstrap_draws=-1,\n",
    "        estimator_type=PyroEstimatorVI,\n",
    "        mvn=1\n",
    "        )\n",
    "\n",
    "        ############################\n",
    "        # second one \n",
    "        ktrx2 = KTRXFull(\n",
    "        response_col=response_col,\n",
    "        date_col='date',\n",
    "\n",
    "        degree_of_freedom=30,\n",
    "        level_knot_scale=1,\n",
    "        level_knot_dates=level_knot_dates,\n",
    "        level_knots=level_knots_stan,\n",
    "\n",
    "        regressor_col=regressor_col,\n",
    "        regressor_sign=['='] * len(regressor_col),\n",
    "        regressor_knot_pooling_loc=[0] * len(regressor_col),\n",
    "        regressor_knot_pooling_scale=[1] * len(regressor_col),\n",
    "        regressor_knot_scale=[.2] * len(regressor_col),\n",
    "        # seasonal_knots_input={},\n",
    "\n",
    "        span_coefficients=0.1,\n",
    "        rho_coefficients=0.1, #.1,.11,.12\n",
    "        prediction_percentiles=[2.5, 97.5],\n",
    "        seed=3000+i, # just to make them different from each other\n",
    "        num_steps=1000,\n",
    "        num_particles=100,\n",
    "        num_sample=1000,\n",
    "        learning_rate=0.01,\n",
    "        learning_rate_total_decay=1.,\n",
    "        verbose=False,\n",
    "        message=100,\n",
    "        n_bootstrap_draws=-1,\n",
    "        estimator_type=PyroEstimatorVI,\n",
    "        )\n",
    "        \n",
    "        # fit the models and recod the times\n",
    "        start_time = time.time()\n",
    "        ktrx1.fit(df=data)\n",
    "        time_1 = time.time() - start_time\n",
    "        \n",
    "        start_time = time.time()\n",
    "        ktrx2.fit(df=data)\n",
    "        time_2 = time.time() - start_time\n",
    "        \n",
    "        # get the predictions \n",
    "        predicted_df_1 = ktrx1.predict(df=data)\n",
    "        predicted_df_2 = ktrx2.predict(df=data)\n",
    "        \n",
    "\n",
    "        \n",
    "        # compare to observations  \n",
    "        SSE_1 = sum((predicted_df_1['prediction'] - data['y'])**2.0 )\n",
    "        SSE_2 = sum((predicted_df_2['prediction'] - data['y'])**2.0 )\n",
    "        \n",
    "        max_misfit_1 = max(abs(predicted_df_1['prediction'] - data['y']) )\n",
    "        max_misfit_2 = max(abs(predicted_df_2['prediction'] - data['y']) )\n",
    "    \n",
    "        out.at[i, 'time_1'] = time_1 \n",
    "        out.at[i, 'time_2'] = time_2 \n",
    "    \n",
    "        out.at[i, 'SSE_1'] = SSE_1 \n",
    "        out.at[i, 'SSE_2'] = SSE_2 \n",
    "        \n",
    "        out.at[i, 'RMSE_1'] = (SSE_1/n)**(0.5) \n",
    "        out.at[i, 'RMSE_2'] = (SSE_2/n)**(0.5) \n",
    "        \n",
    "        \n",
    "        out.at[i, 'max_error_1'] = max_misfit_1\n",
    "        out.at[i, 'max_error_2'] = max_misfit_2\n",
    "        \n",
    "        #compare to true values \n",
    "        coef_df_1= ktrx1.get_regression_coefs(\n",
    "        aggregate_method='median',\n",
    "        include_ci=False)\n",
    "        \n",
    "        coef_df_2= ktrx2.get_regression_coefs(\n",
    "        aggregate_method='median',\n",
    "        include_ci=False)\n",
    "        \n",
    "        SSE_beta1_1 = sum((coef_df_1['x1']-data['beta1'])**2.0)\n",
    "        SSE_beta2_1 = sum((coef_df_1['x2']-data['beta2'])**2.0)\n",
    "        SSE_beta3_1 = sum((coef_df_1['x3']-data['beta3'])**2.0)\n",
    "        SSE_beta1_2 = sum((coef_df_2['x1']-data['beta1'])**2.0)\n",
    "        SSE_beta2_2 = sum((coef_df_2['x2']-data['beta2'])**2.0)\n",
    "        SSE_beta3_2 = sum((coef_df_2['x3']-data['beta3'])**2.0)    \n",
    "        \n",
    "        out.at[i,'SSE_beta1_1'] = SSE_beta1_1\n",
    "        out.at[i,'SSE_beta2_1'] = SSE_beta2_1\n",
    "        out.at[i,'SSE_beta3_1'] = SSE_beta3_1\n",
    "        out.at[i,'SSE_beta1_2'] = SSE_beta1_2\n",
    "        out.at[i,'SSE_beta2_2'] = SSE_beta2_2\n",
    "        out.at[i,'SSE_beta3_2'] = SSE_beta3_2\n",
    "        \n",
    "    return(out)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-appraisal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Guessed max_plate_nesting = 1\n"
     ]
    }
   ],
   "source": [
    "multiple_test(N=10,n=300, sim_type='sea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_test(N=3,n=300, sim_type='rw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data_rw(n=10, RS=8888, p=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-princeton",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T18:07:01.202428Z",
     "start_time": "2021-04-06T18:06:09.057819Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-baking",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T18:07:21.859418Z",
     "start_time": "2021-04-06T18:07:01.205020Z"
    }
   },
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-talent",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T18:07:21.890535Z",
     "start_time": "2021-04-06T18:07:21.861880Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-accuracy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-06T18:07:27.213968Z",
     "start_time": "2021-04-06T18:07:26.552497Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-porcelain",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orbit",
   "language": "python",
   "name": "orbit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
